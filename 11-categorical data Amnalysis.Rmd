---
title: "11. Categorical data analysis"
author: "Lieven Clement"
date: "statOmics, Ghent University (https://statomics.github.io)"
output:
    html_document:
      code_download: true
      theme: cosmo
      toc: true
      toc_float: true
      highlight: tango
      number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE, comment = NA, echo = TRUE,
                      message = FALSE, warning = FALSE)
library(Rmisc)
library(tidyverse)
library(NHANES)
```


# Introduction 

- Until now we used models for a continuous response in function of categorical or continuous predictor.
- Here we will focus on a categorical response.
- We focus on the association on a categorical outcome and a categorical predictor and touch upon methods to model a categorical outcome with a continuous response. 


---

# Test for a proportion 

##Saksen-study

- Fairly closed populatie (few migration)
- Probability that an unborn child is male?

```{r}
boys <- 3175
n <- 6155
```

- On `r n` unborn children `r boys` boys are observed.
- Is there a difference in the probability that an unborn child is a boy or a girl? 

---

- The data are derived from a binary random variable $X$

  - $X=1$ for a boy and 
  - $X=0$ for a girl.

- Note: count problem: the outcome is a count (number of boys) 

- Formally we have considered a population of unborn children where each individual is characterized by a 0 or 1.

---

## Bernoulli verdeling

- Binairy data can be modelled using a Bernoulli distribution:
  \begin{eqnarray*}
X_i &\sim& B(\pi) \text{ met}\\
B(\pi)&=&\pi^{X_i}(1-\pi)^{(1-X_i)},
\end{eqnarray*}

- it has one model parameter $\pi$

    - Expected value of $X_i$: $\text{E}[X_i]=\pi,$
    - Proportion of unborn boys (children with $X=1$) in the population.
    - Hence $\pi$ is the probability that a random individual from the population is a boy (an observation with $X=1$).

- The variance of Bernoulli data is also related to $\pi$.
$$\text{Var}[X_i]=\pi (1-\pi).$$

---

Some Bernoulli probability distributions

```{r, out.width='100%', fig.asp=1, fig.align='center',echo=FALSE}
par(mfrow=c(1,3),pty="s")
probs=c(0.25,.5,.75)
for (i in 1:length(probs))
{
plot(c(0,1),c(1-probs[i],probs[i]),ylim=c(0,1),type="h",xaxt="n",xlab="X",ylab="Kans (Dichtheid)",main= as.expression(substitute(pi == val,list(val=probs[i]))),lwd=3)
axis(1,at=c(0,1))
}
```

---

- In Saksenstudie worden lukraak 6155 observaties getrokken uit de populatie.
- We schatten $\pi$ als het steekproefgemiddelde :
$$\hat \pi = \bar X = \frac{\sum\limits_{i=1}^n X_i}{n},$$

```{r}
pi=boys/n
pi
```

In ons voorbeeld is $\bar x =$ `r boys` / `r n` = `r format(pi*100,digits=3)`%.

---

##8.2.1. Binomiale test
- Geeft feit dat `r format(pi*100,digit=3)`% van de kinderen in de studie mannelijk zijn, voldoende overtuigingskracht om te beweren dat er meer kans is dat een ongeboren kind een jongen is dan een meisje.

- Statistiche toets voor
  $$H_0: \pi=1/2 \text{ versus } H_1: \pi\neq 1/2,$$

- Daarvoor moeten we verdeling van de
   - $X$ en $\bar X$
   - of van de som $S=n\bar X$ kennen.

---


- Stel  $H_0:\pi=1/2$ is waar (voorkomen van jongens en meisjes in populatie even waarschijnlijk)
- Lukrake trekking van ????n individu uit de populatie, kans op een jongen $$P(X=1)=\pi=1/2.$$
- Twee kinderen onafhankelijk van elkaar (en de populatie $\approx \infty$):
  - Kans $\pi=1/2$ op jongen voor zowel eerste als tweede kind (onafhankelijk van elkaar)
  - Uitkomsten $(x_1, x_2)$ voor beide kinderen hebben dan 4 mogelijke waarden:
    $(0,0),(0,1),(1,0)\text{ en }(1,1).$
  - Deze komen elk voor met kans $1/4 = 1/2 \times 1/2$.

- Toevalsveranderlijke $S$ die som van uitkomsten weergeeft kan volgende waarden aannemen:

$(x_1,x_2)$|$s$|$P(S = s)$|
|:---:|:---:|:---:|
(0,0)|0|1/4|
(0,1), (1,0)|1|1/2|
(1,1)|2|1/4|

---

###Algemeen: $n$ onafhankelijke observaties

- Kans $\pi$ op "succes" (uitkomst 1) voor elke observatie
- Totaal aantal successen $S$ (som van alle 1-en) kan $n+1$ mogelijke waarden hebben
  $$S=k\text{, met }k=0,\ldots,n$$
- Verdeling van $S$?
\begin{equation}
P(S=k) = \left (
\begin{array}{c}
n \\
k \\
\end{array}
\right ) \pi^k (1-\pi)^{n-k}  (\#eq:binomk)
\end{equation}
- $1-\pi$: kans op mislukking in 1 enkele trekking (uitkomst met 0 genoteerd) en
-  binomiaalco??fficient
\begin{equation*}
\left (
\begin{array}{c}
n \\
k \\
\end{array}
\right ) = \frac{n \times (n-1) \times ...\times (n-k+1) }{ k!} = \frac{ n!}{ k!(n-k)! }
\end{equation*}

- In R kan je de kansen van binomiale verdeling voor elke $S=k$ opvragen met `dbinom(k,n,p)`


---

### Binomiale Verdeling

Een toevalsveranderlijke $S$ een kansverdeling in Model \@ref(eq:binomk):

-  *Binomiaal verdeelde toevalsveranderlijke* met bijhorende *Binomiale kansverdeling*
- parameters

    - $n$ (d.i. het aantal trekkingen of, equivalent, de maximale
uitkomstwaarde)  
    - $\pi$ (de kans op een `succes' bij elke trekking).

- Kans berekenen $k$ gebeurtenissen zich voordoen op $n$ onafhankelijke experimenten waarbij kans op 1 zo'n gebeurtenis per experiment, $\pi$ bedraagt.
- Voor analyse van gegevens die slechts 2 mogelijke waarden kunnen aannemen.
- Bijvoorbeeld: al dan niet besmet met HIV, wild type van een gen vs een mutant,...
- Gebruik: Proporties of risico's op een gebeurtenis van een bepaald type vergelijken tussen verschillende groepen.

---

### Een grafische weergave van enkele Binomiale kansverdelingen.

```{r binoms,fig.cap='Binomiale verdelingen.', out.width='80%', fig.asp=.8, fig.align='center',echo=FALSE}
par(mfrow=c(2,2))
probs=c(0.25,.5,.75)
for (i in 1:length(probs))
{
plot(0:10,dbinom(0:10,prob=probs[i],size=10),ylim=c(0,1),type="h",xlab="X",ylab="Kans (Dichtheid)",main= as.expression(substitute(pi == val,list(val=paste(probs[i],", nobs=10")))),lwd=3)
}
plot(2925:3225,dbinom(2925:3225,prob=.5,size=n),type="h",xlab="X",ylab="Kans (Dichtheid)",main= as.expression(substitute(pi == val,list(val=paste0("0.5, nobs=",n)))))
```

---

Toetsstatistieken voor $$H_0:\pi=1/2\text{ versus }H_1:\pi\neq 1/2$$


- $\bar X-1/2$ of, equivalent,
- $\Delta=n(\bar X-\pi_0)=S-s_0$.
- Verdeling van deze laatste toetsstatistiek volgt rechtstreeks uit de Binomiale verdeling:
  - We observeren $s=$ `r boys` en dus $\delta=s-s_0=$ `r boys` $-$ `r n` $\times 0.5=$ `r boys-n/2`.
  - In veronderstelling dat jongens en meisjes even waarschijnlijk zijn (d.i. onder de nulhypothese $H_0:\pi=1/2$), bekomen we de bijhorende tweezijdige p-waarde:
    $$p=\text{P}_0\left[S-s_0\geq \vert \delta\vert \right] + \text{P}_0\left[S-s_0\leq - \vert \delta\vert \right].$$

- Merk op dat we dit kunnen herschrijven in termen van S.
$$p=\text{P}_0\left[S\geq s_0+ \vert \delta\vert \right] + \text{P}_0\left[S \leq s_0 - \vert \delta\vert \right].$$

---

- Voor ons voorbeeld kunnen we deze kansen als volgt berekenen:

\begin{eqnarray*}
\text{P}_0\left[S\geq s_0+ \vert \delta\vert \right] &=& P(S \geq 6155 \times 0.5 + \vert 3175 - 6155 \times 0.5\vert ) \\&=& P(S \geq 3175)\\
&= &P(S= 3175) + P(S=3176) + ... + P(S=6155)\\
& =& 0.0067\\\\
\text{P}_0\left[S \leq s_0 - \vert \delta\vert \right] &=& P(S \leq  6155 \times 0.5 - \vert 3175- 6155 \times 0.5\vert) \\&=& P(S \leq 2980)\\ &= &P(S=0) + ... + P(S=2980) \\
&=&0.0067
\end{eqnarray*}

- Binomiale distributie is symmetrisch als $\pi=1/2$:
$$\text{P}_0\left[S\geq s_0+ \vert \delta\vert \right] = \text{P}_0\left[S \leq s_0 - \vert \delta\vert \right]$$
- Dat is niet langer het geval wanneer $\pi$ afwijkt van 0.5.  

---


```{r}
pi0 <- 0.5; s0 <- pi0 *n
delta <- abs(boys- s0)
delta

sUp <- s0 + delta
sDown <- s0 -delta
c(sDown,sUp)

#Leg uit!
pUp <- 1-pbinom(sUp-1,n,pi0)
pDown <- pbinom(sDown,n,pi0)
p <- pUp+pDown
c(pUp,pDown, p)
```

---


- Als $\pi= 1/2$, kans om door toeval minstens $\delta=$ `r delta` jongens meer of minder te observeren dan het gemiddelde onder $H_0: s_0=$ `r s0` , slechts `r format(p*100,digits=3)`% is: **de $p$-waarde van de binomiale test.**  
- Heel onwaarschijnlijk om een dergelijk groot aantal jongens te observeren als in realiteit jongens en meisjes even waarschijnlijk zijn.
- Drukt uit dat de onderstelling dat jongens en meisjes even waarschijnlijk zijn, weinig gesteund wordt door de data.

---

```{r, out.width='100%', fig.asp=.8, fig.align='center',echo=FALSE}
plot(s0+seq(-150.5,150.5,1),dbinom(s0+seq(-150.5,150.5,1),prob=.5,size=n),type="h",xlab="X",ylab="Kans (Dichtheid)",main= as.expression(substitute(pi == val,list(val=paste0("0.5, nobs=",n)))),ylim=c(-.0009,0.011))
abline(v=s0,lwd=2,col=4)
abline(v=boys,lwd=2,col=2)
abline(v=sDown,lwd=1,col=2,lty=2)
text(c(sDown,s0,boys,boys),c(rep(0.011,3),0.01),labels=c(expression(paste(s[0]-delta)),expression(s[0]),expression(s==s[0]+delta),as.expression(substitute(s==val,list(val=boys)))),pos=4,col=c(2,4,2))
text(sDown-50,-.0005,label="p-waarde",col=2,pos=4)
text(sUp,-.0005,label="p-waarde",col=2,pos=4)
arrows(s0+1500.5,-.0009,sUp,-.0009,col=2,lwd=2,angle=20,length=.1)
arrows(s0-1500.5,-.0009,sDown,-.0009,col=2,lwd=2,angle=20,length=.1)
```

---

De test kan eveneens worden uitgevoerd a.d.h.v. de `binomial.test` functie in R.

```{r}
binom.test(x=boys,n=n,p=pi0)
```

Op het 5% significantie-niveau besluiten we dat er gemiddeld meer kans is dat een ongeboren kind mannelijk dan vrouwelijk is.

---

### 8.2.2. Betrouwbaarheidsinterval op een proportie

- Schatter van de proportie van jongens in de populatie, is steekproefgemiddelde $\hat \pi=\bar x=$ `r format(pi,digits=3)`
- Standaard error is
$$SE_{\bar x}=\sqrt{\frac{\text{Var}[X]}{n}}=\sqrt{\frac{\pi(1-\pi)}{n}}$$
- We kunnen dit schatten o.b.v. de steekproef: $SE_{\bar x}=\sqrt{\frac{\hat\pi(1-\hat\pi)}{n}}=$ `r format(sqrt(pi*(1-pi)/n),digits=2)`.
- 95% BI via centrale limietstelling: $\hat\pi \pm 1.96 SE_{\hat\pi}.$

```{r}
se=sqrt(pi*(1-pi)/n)
pi+c(-1,1)*qnorm(0.975)*se
```

---

###Betrouwbaarheidsinterval op een proportie in kleine steekproef?


- Inverteren van de one-sample test voor proporties.
- Stop alle waarden $\pi_0$ die niet verworpen worden door binomiale test op het 5% significantieniveau in BI
- Is ge??mplementeerd in de `binom.test` functie.

```{r}
BI <- binom.test(x=boys,n=n,p=pi0)$conf.int
BI
```

---

We verfi??ren dit nu:
```{r}
binom.test(x=boys,n=n,p=BI[1],alternative="greater")
```

---

```{r}
binom.test(x=boys,n=n,p=BI[2],alternative="less")
```

- Het exacte BI is te verkiezen boven het BI dat gebaseerd is op de CLT.
- Voor Saksen-studie ligt BI o.b.v. CLT heel dicht bij exacte BI: grote steekproef ($n=$ `r n`).

---

### 8.2.3. Conclusie

- Merk op dat het testen voor een proportie kan gezien worden als het equivalent van een one-sample t-test voor binaire data.

- Voor de Saksen populatie besluiten we op het 5% significantieniveau dat er meer kans is dat een ongeboren kind mannelijk dan vrouwelijk is ($p=$ `r round(binom.test(x=boys,n=n,p=pi0)$p.value,3)`).
De kans dat een ongeboren kind mannelijk is, bedraagt `r format(pi*100,digits=3)`% (95% BI [`r paste(format(BI*100,digits=3),collapse=",")`]%).

---

# 8.3. Toets voor associatie tussen 2 kwalitatieve variabelen
## 8.3.1. Gepaarde gegevens

- 2 keer zelfde individu meten
- bijvoorbeeld, v????r en na blootstelling aan de experimentele stof
- telkens de categorische uitkomst te observeren.
- Hier enkel: *gepaarde binaire uitkomsten*
- Statistische analyse moet rekening houden met de paring.

---

### 8.3.1.1. Voorbeeld:  partnerkeuze van seksueel mature vrouwelijke *Campbelli* dwerghamster (Rogovin et al. 2017)

```{r, out.width='70%', fig.asp=1, fig.align='center',echo=FALSE}
library(plotrix)
par(mar=c(0,0,0,0),mai=c(0,0,0,0))
plot(0,0,axes=FALSE,xlab="",ylab="",col=0,xlim=c(0,3),ylim=c(0,3))
rect(0,0,3,3)
lines(c(1,1),c(0,3))
lines(c(2,2),c(0,3))
lines(c(1,1),c(1,2),lwd=2)
lines(c(1,1),c(1,2),lwd=4)
lines(c(2,2),c(1,2),lwd=4)
rect(1.45,1,1.55,1.3)
draw.circle(1.5,1.36,0.05)
lines(c(1.5,1.5),c(1,.85))
text(1.5,1.15,"\\VE",vfont=c("sans serif","bold"),cex=1.3)
rect(0.5,1.05,0.8,1.15)
draw.circle(0.86,1.1,0.05)
lines(c(0.5,0.35),c(1.1,1.1))
lines(c(0.8,0),c(1.1,1.5),lty=2)
text(0.65,1.1,"\\MA",vfont=c("sans serif","bold"),cex=1.3)
rect(2.5,1.95,2.2,1.85)
draw.circle(2.14,1.9,0.05)
lines(c(2.5,2.65),c(1.9,1.9))
lines(c(2.2,3),c(1.9,1.5),lty=2)
text(2.35,1.9,"\\MA",vfont=c("sans serif","bold"),cex=1.3)
```

---

###Voorbeeld:  partnerkeuze van seksueel mature vrouwelijke *Campbelli* dwerghamster (Rogovin et al. 2017)

- Na 3 minuten, scheidingswand weg
- aggressief vs niet-agressief mannentje
- Elk vrouwtje onderging tweemaal de test: na verblijf in

    - vijandige omgeving (hoge populatie, weinig voedsel, veel concurrentie)
    - vriendelijkere omgeving


```{r catHamster, echo=FALSE}
hamster <- matrix(c(3,17,1,13),ncol=2,byrow=TRUE)
rownames(hamster) <- c("vijandig-agressief", "vijandig-niet-agressief")
colnames(hamster) <- c("vriendelijk-agressief","vriendelijk-niet-agressief")
hamsterTot=matrix(0,nrow=3,ncol=3)
hamsterTot[1:2,1:2]=hamster
hamsterTot[3,1:2]=colSums(hamster)
hamsterTot[,3]=rowSums(hamsterTot[,1:2])
hamsterLetters=matrix(c(" (e)"," (f)",""," (g)"," (h)","","","",""),ncol=3,byrow=TRUE)
hamsterTot=matrix(paste0(hamsterTot,hamsterLetters),byrow=FALSE,ncol=3)
colnames(hamsterTot)<-c(colnames(hamster),"totaal")
rownames(hamsterTot)<-c(rownames(hamster),"totaal")
knitr::kable(hamsterTot,caption="Kruistabel van partnerkeuze bij dwerghamster.",booktabs = TRUE)
```

---
```{r,echo=FALSE}
knitr::kable(hamsterTot,booktabs = TRUE)
```

- $\pi_1=P[\text{agressief mannetje } \vert \text{ verblijf vijandige omgeving}$
- $\hat pi_1=(e+f)/n$, waarbij $n=e+f+g+h$.

- $\pi_0=P[\text{agressief mannetje } \vert \text{ verblijf vriendelijke omgeving}$
- $\hat pi_0=(e+g)/n$
-Absoluut riscoverschil (ARV)
\begin{equation*}
\widehat{\text{ARV}}=\hat\pi_1-\hat\pi_0=\frac{e+f}{n}-\frac{e+g}{n}=\frac{f-g}{n}
\end{equation*}
- Enkel be??nvloed door aantallen discordante paren $f$ en $g$

---

- Standaard error op ARV
\begin{equation*}
\text{SE}_{\widehat{\text{ARV}}}=\frac{1}{n}\sqrt{f+g-\frac{(f-g)^2}{n}}
\end{equation*}

- Als er voldoende gegevens zijn, kan men een $(1-\alpha)100\%$ BI op ARV
$$\left[\widehat{\text{ARV}}-z_{\alpha/2}\text{SE}_{\widehat{\text{ARV}}},\widehat{\text{ARV}}-z_{\alpha/2}\text{SE}_{\widehat{\text{ARV}}}\right]$$
of
$$\left[\frac{f-g}{n}-\frac{z_{\alpha/2}}{n}\sqrt{f+g-\frac{(f-g)^2}{n}},\frac{f-g}{n}+\frac{z_{\alpha/2}}{n}\sqrt{f+g-\frac{(f-g)^2}{n}}\right] $$

---

```{r}
hamster <- matrix(c(3,17,1,13),ncol=2,byrow=TRUE)
rownames(hamster) <- c("vijandig-agressief", "vijandig-niet-agressief")
colnames(hamster) <- c("vriendelijk-agressief","vriendelijk-niet-agressief")

f=hamster[1,2]; g=hamster[2,1] ;n=sum(hamster)
riskdiff=(f-g)/n
riskdiff
se=sqrt(f+g-(f-g)^2/n)/n
se
bi=riskdiff+c(-1,1)*qnorm(0.975)*se
bi
```

---

\begin{equation*}
\widehat{\text{ARV}}=\frac{17-1}{34}=0.471
\end{equation*}
of 47.1%.
- De standaard error
\begin{equation*}
\text{SE}_{\widehat{\text{ARV}}}=\frac{1}{34}\sqrt{17+1-\frac{(17-1)^2}{34}}=0.0952
\end{equation*}
- Een 95\% betrouwbaarheidsinterval voor het absolute risicoverschil op de keuze van een agressief mannetje tussen een verblijf in een vijandige en vriendelijke omgeving is bijgevolg
\begin{equation*}
\left[0.471-1.96\times 0.0952,0.471+1.96\times 0.0952\right]=[0.284,0.658]
\end{equation*}
- We hebben dus geschat dat het absolute risico met 95% kans in het interval [28.4,65.8]% ligt.

---

### 8.3.1.2. McNemar test
```{r,echo=FALSE}
knitr::kable(hamsterTot,booktabs = TRUE)
```

- Toetsen of de risico's verschillen tussen de vijandige en vriendelijke omgeving.
- Enkel de discordante paren leveren hier informatie over.
- $f>g$ indicatie tegen $H_0: partnerkeuze niet geassocieerd met omgeving$
- Kans evalueren dat in een lukraak discordant paar, vrouwtje na verblijf in een vijandige omgeving kiest voor het agressieve mannetje.
- Deze kans wordt geschat als
  $$\frac{f}{f+g}$$

---

  \begin{eqnarray*}
  \text{E}\left[f/(f+g)\right]&\stackrel{H_0}{=}& 0.5\\
  f & \stackrel{H_0}{\sim}& \text{Binom}(n=f+g,\pi=0.5)\\
  \text{SE}_{\frac{f}{f+g}} & \stackrel{H_0}{=}& \sqrt{(f+g)\times 0.5\times 0.5}=\frac{\sqrt{f+g}}{2}
\end{eqnarray*}

---

- Asymptotisch one-sample z-test (o.b.v. normale verdeling)

\begin{equation*}
z=\frac{f-(f+g)/2}{\sqrt{f+g}/2}=\frac{f-g}{\sqrt{f+g}}
\end{equation*}

- De Normale benadering is goed als $$f \times g/(f+g) \geq 5$$

- In kleine steekproeven is het meer aangewezen om een continu??teitscorrectie te gebruiken d.m.v. de toetsingsgrootheid
\begin{equation*}
\frac{|f-g|-1}{\sqrt{f+g}}
\end{equation*}

De **Mc Nemar test** analogon van de gepaarde t-test voor binaire, kwalitatieve i.p.v. continue variabelen.

---

We voeren nu de analyse uit voor het hamstervoorbeeld in R:

```{r}
correct=f*g/(f+g)
correct
#continuiteitscorrectie
t= (abs(f-g)-1)/sqrt(f+g); t
p=(1-pnorm(t))*2; p
```

- Voor het dwerghamster voorbeeld observeren we dat
$f\times g/(f+g)=$ `r format(correct,digits=3)` $<5$ $\rightarrow$ continu??teitscorrectie
- De kans dat een Normaal verdeelde toevalsveranderlijke groter is
dan `r format(t,digits=3)` of kleiner is dan  `r format(-t,digits=3)` bedraagt `r format(p*100,digits=3)`%: *p-waarde*

---

In R kan de analyse ook worden uitgevoerd a.d.h.v. de `mcnemar.test` functie
```{r}
mcnemar.test(hamster)
```


- We verwerpen bijgevolg de nulhypothese op het 5% significantieniveau en
- Besluiten dat de parternkeuze extreem significant geassocieerd is met de omgeving.

- We zien dat hier eveneens de continu??teitscorrectie werd uitgevoerd en dat we exact dezelfde p-waarde bekomen.

---

- Normale benadering van deze toetstatistiek niet ideaal
is omdat $f \times g/(f+g)=$ `r format(correct,digits=3)` $<5$.

- Aangewezen om een exacte toets te gebruiken op basis van binomiale test

```{r}
binom.test(x=f,n=f+g,p=0.5)
```

---

#### 8.3.1.3. Conclusie

- Op basis van de exacte test besluiten we eveneens dat de parternkeuze extreem significant geassocieerd is met de omgeving ($p<0.001$).
- De kans op de keuze van een agressief mannetje ligt `r format(riskdiff*100,digits=3)`% hoger als een dwerghamster vrouwtje zich in een vijandige omgeving bevindt dan wanneer ze zich in een vriendelijke omgeving bevindt (95% BI [`r paste(format(bi*100,digits=3),collapse=",")`]%).

---

##8.3.2. Ongepaarde gegevens
###Genetische associatie studie (zie Sectie 3.6.2)
- Genetische associatiestudie polymorfismen in het BRCA1 gen geassocieerd is met borstkanker?
- Retrospectieve case-controle studie met 800 borstkankercases en 572 controles
- R object is opgeslagen in de file `brca.rda`

```{r}
load("dataset/brca.rda")
head(brca)
summary(brca)
```

---

```{r, tidy=FALSE,echo=FALSE}
brcaHlp=data.frame(Genotype=c("Pro/Pro","Pro/Leu","Leu/Leu","Totaal"),Controles=c("266 (a)","250 (b)","56 (c)","572 (a+b+c)"),Cases=c("342 (d)","369 (e)","89 (f)","800 (d+e+f)"),Totaal=c("608 (a+d)","619 (b+e)","145 (c+f)","1372 (n)"))
knitr::kable(brcaHlp,
  booktabs = TRUE
)
```

- In case-controle studies kiest men een vast aantal cases en controles en spoort men voor hen op welke blootstellingen ze in het verleden ondervonden hebben.
- Dergelijke studies noemt men ook retrospectief
- Onmogelijk om het risico's and riscoverschillen op borstkanker te schatten: proportie van cases en controles weerspiegelt populatie niet!

---

```{r, tidy=FALSE,echo=FALSE}
brcaHlp=data.frame(Genotype=c("Pro/Pro","Pro/Leu","Leu/Leu","Totaal"),Controles=c("266 (a)","250 (b)","56 (c)","572 (a+b+c)"),Cases=c("342 (d)","369 (e)","89 (f)","800 (d+e+f)"),Totaal=c("608 (a+d)","619 (b+e)","145 (c+f)","1372 (n)"))
knitr::kable(brcaHlp,
  booktabs = TRUE
)
```

- Wel mogelijk om kans te schatten om allel Leu/Leu
    - cases: $\pi_1=f/(d+e+f)=89/800=11.1\%$
    - controles:$\pi_0=c/(a+b+c)=56/572=9.8\%$
- Relatief risico op blootstelling voor cases versus
controles is bijgevolg $11.1/9.8=1.14$.
- Vrouwen met borstkanker hebben dus 14% meer kans om de allelcombinatie Leu/Leu te hebben op het BRCA1 gen dan vrouwen zonder borstkanker.
- Dit suggereert een associatie, maar drukt iet uit hoeveel hoger het risico op borstkanker is voor vrouwen met de allelcombinatie Leu/Leu dan voor andere vrouwen
- Andere risicomaat?

---

\begin{equation*}
Odds=\frac{p}{1-p}
\end{equation*}
waarbij $p$ de kans is op die gebeurtenis.

Transformatie van het risico, met volgende eigenschappen:

  - de odds neemt waarden aan tussen nul en oneindig.

  - de odds is gelijk aan 1 als en slechts als de kans zelf gelijk is aan
1/2.

  - de odds neemt toe als de kans toeneemt.

- populair bij gokkers: hoeveel waarschijnlijker het is om te winnen dan om te verliezen

---

```{r, tidy=FALSE,echo=FALSE}
brcaHlp=data.frame(Genotype=c("Pro/Pro","Pro/Leu","Leu/Leu","Totaal"),Controles=c("266 (a)","250 (b)","56 (c)","572 (a+b+c)"),Cases=c("342 (d)","369 (e)","89 (f)","800 (d+e+f)"),Totaal=c("608 (a+d)","619 (b+e)","145 (c+f)","1372 (n)"))
knitr::kable(brcaHlp,
  booktabs = TRUE
)
```

Odds op allel Leu/Leu

- Cases: $\mbox{odds}_1=\frac{ f/(d+e+f)}{(d+e)/(d+e+f)}=f/(d+e)=89/711=0.125$. Vrouwen met borstkanker hebben ongeveer 8 keer meer kans om de allelcombinatie Leu/Leu niet te hebben op het BRCA1 gen dan om het wel te hebben.
- Controles: $\mbox{odds}_2=c/(a+b)=56/516=0.109$.

- Associatie tussen blootstelling en uitkomst:
$$
OR_{Leu/Leu}=\frac{\mbox{odds}_T}{\mbox{odds}_C}= \frac{f/(d+e)}{c/(a+b)}=\frac{f/(d+e)}{c/(a+b)}=1.15
$$

---


```{r, tidy=FALSE,echo=FALSE}
brcaHlp=data.frame(Genotype=c("Pro/Pro","Pro/Leu","Leu/Leu","Totaal"),Controles=c("266 (a)","250 (b)","56 (c)","572 (a+b+c)"),Cases=c("342 (d)","369 (e)","89 (f)","800 (d+e+f)"),Totaal=c("608 (a+d)","619 (b+e)","145 (c+f)","1372 (n)"))
knitr::kable(brcaHlp,
  booktabs = TRUE
)
```

- Was de bovenstaande studie echter een volledig lukrake steekproef geweest
(waarbij het aantal cases en controles niet per design werden vastgelegd),
- dan konden we daar ook de odds ratio op borstkanker berekenen voor mensen
met versus zonder het allel Leu/leu.
\begin{equation*}
OR_{case}=\frac{ \frac{ f}{c}}{ \frac{(d+e)}{(a+b)}} = \frac{f(a+b)}{c(d+e)}=OR_{Leu/Leu}=1.15,
\end{equation*}
- OR is een symmetrische maat! OR op borstkanker kan wel worden geschat!
- De odds op borstkanker is bijgevolg 15% hoger bij vrouwen met die specifieke allelcombinatie.

---

- Is verschil groot genoeg zodat we het effect die we in de steekproef zien kunnen veralgemenen naar de populatie toe.

- Hiertoe zullen we de kruistabel eerst herschrijven tot een 2x2 tabel

```{r leu4, tidy=FALSE,echo=FALSE}
brcaTab2 <- table(brca$variant2,brca$cancer)
brcaHlp2=data.frame(Genotype=c("andere","Leu/Leu","Totaal"),Controles=c("516 (a)","56 (b)","572 (a+b)"),Cases=c("711 (c)","89 (d)","800 (c+d)"),Totaal=c("1227 (a+c)","145 (b+d)","1372 (n)"))
knitr::kable(brcaHlp2,
  booktabs = TRUE
)
```

---

## 8.3.3. De Pearson Chi-kwadraat test voor ongepaarde gegevens

- Testen voor associatie tussen de categorische blootstelling (bvb. variant, X) en de categorische uitkomst (bvb. ziekte, Y).
$$H_0: \text{Er is geen associatie tussen } X \text{ en } Y \text{ vs } H_1: X \text{ en } Y \text{ zijn geassocieerd}$$

- Beschouw de rijtotalen $n_\text{andere}=a+c$, $n_\text{leu,leu}=b+d$ enerzijds en
- de kolomtotalen $n_\text{contr}=a+b$ en $n_\text{case}=c+d$ anderzijds.
- Zij verstrekken informatie over de *marginale verdeling* van de blootstelling (bvb. variant, X) en de uitkomst (bvb. ziekte, Y),
maar niet over de associatie tussen die veranderlijken.
- Onder $H_0$ zijn $X$ en $Y$ onafhankelijk zijn en verwacht men een proportie $(b+d)/n$
van $a+b$ controles met een Leu/Leu variant, of dat $(a+b)(b+d)/n$ een Leu/Leu variant hebben
- Analoog kan men verwachte aantal $E_{ij}$ berekenen dat onder de nulhypothese in *elke cel* van de $2\times 2$ tabel zou liggen.

---

- $E_{11}$ = het verwachte aantal onder $H_0$ in de (1,1)-cel = `r sum(brcaTab2[1,])` $\times$ `r sum(brcaTab2[,1])`/`r sum(brcaTab2)` = `r format(sum(brcaTab2[1,])*sum(brcaTab2[,1])/sum(brcaTab2),digits=4)` ;

- $E_{12}$ = het verwachte aantal onder $H_0$ in de (1,2)-cel = `r sum(brcaTab2[1,])` $\times$ `r sum(brcaTab2[,2])`/`r sum(brcaTab2)` = `r format(sum(brcaTab2[1,])*sum(brcaTab2[,2])/sum(brcaTab2),digits=4)` ;

- $E_{21}$ = het verwachte aantal onder $H_0$ in de (2,1)-cel = `r sum(brcaTab2[2,])` $\times$ `r sum(brcaTab2[,1])`/`r sum(brcaTab2)` = `r format(sum(brcaTab2[2,])*sum(brcaTab2[,1])/sum(brcaTab2),digits=4)` ;

- $E_{22}$ = het verwachte aantal onder $H_0$ in de (2,2)-cel = `r sum(brcaTab2[2,])` $\times$ `r sum(brcaTab2[,2])`/`r sum(brcaTab2)` = `r format(sum(brcaTab2[2,])*sum(brcaTab2[,2])/sum(brcaTab2),digits=4)` ;

Toetsstatistiek:
\begin{eqnarray*}
X^2 &=& \frac{\left (|O_{11} - E_{11}| - .5 \right)^2 }{ E_{11}} + \frac{
\left ( |O_{12} - E_{12}| - .5 \right)^2 }{E_{12} }+ \\
&&\quad\quad
\frac{ \left ( |O_{21}
- E_{21}| - .5 \right)^2 }{E_{21}}+ \frac{ \left ( |O_{22} - E_{22}| - .5
\right)^2 }{E_{22} }\\
 X^2 &\stackrel{H_0}{\longrightarrow}& \chi^2(df=1)
\end{eqnarray*}

---

```{r, out.width='100%', fig.asp=.8, fig.align='center',echo=FALSE}
grid=seq(0,10,.1)
plot(grid,dchisq(grid,1),type="l",lwd=2)
dfs=c(1,2,5)
for (i in 2:3)
	lines(grid,dchisq(grid,dfs[i]),col=i,lwd=2)
legend("topright",lty=1,lwd=2,col=1:3,legend=sapply(dfs, function(d) as.expression(substitute(chi[df==val]^2,list(val=d)))))
```

---

- Een grote waarde van de toetsingsgrootheid geeft een indicatie van een
afwijking van de nulhypothese.
- Concreet zal een toets op het $\alpha 100\%$
significantieniveau de nulhypothese verwerpen zodra de geobserveerde waarde
van de toetsingsgrootheid het $100\%(1-\alpha)$-percentiel, $\chi^2_{1,
\alpha}$, van de $\chi^2_1$-verdeling overschrijdt.
- Ze kan niet verwerpen in
het andere geval.
- De p-waarde voor een 2-zijdige toets is in dit geval de
kans om een grotere waarde voor de toetsingsgrootheid te observeren dan de
geobserveerde waarde $x^2$ als de nulhypothese waar is.
- Dit is de kans dat
een $\chi^2_1$-verdeelde toevalsveranderlijke waarden groter dan $x^2$
aanneemt.

---

```{r}
expected <- matrix(0,nrow=2,ncol=2)
for (i in 1:2)
	for (j in 1:2)
		expected[i,j] <-
			sum(brcaTab2[i,])*sum(brcaTab2[,j])/sum(brcaTab2)
expected
x2 <- sum((abs(brcaTab2-expected) - .5)^2/expected)
1-pchisq(x2,1)
```

---

- Omdat de observaties $O_{ij}$ in feite discrete getallen zijn, kan de
toetsingsgrootheid $X^2$ slechts discrete waarden aannemen en kan een
continue verdeling zoals de $\chi^2_1$-verdeling slechts een benadering zijn
voor haar werkelijke verdeling.
- Om de discrete verdeling beter bij de
continue $\chi^2_1$-verdeling te doen aansluiten, heeft men in de
uitdrukking van de toetsingsgrootheid voor elke cel telkens 0.5 afgetrokken.
- Dit wordt een
*continu??teitscorrectie* genoemd.
- In dit geval gaat het om de
correctie van Yates en noemt men deze toets dan ook de *Pearson
Chi-kwadraat toets met Yates correctie*.
- Wanneer de correctie niet gebruikt
wordt (d.w.z. wanneer de getallen `0.5' in de uitdrukking voor $X^2$ door 0
vervangen worden), dan spreekt men van de *Pearson Chi-kwadraat toets*.

---

In R kan je deze toetsen uitvoeren door de optie \texttt{correct} op TRUE of FALSE te zetten:

```{r}
chisq.test(brcaTab2)
chisq.test(brcaTab2,correct=FALSE)
```

---

- Zelfs met continu??teitscorrectie is $\chi^2_1$ benadering slechts
verantwoord als in geen enkele van de cellen het verwachte aantal onder
$H_0$ kleiner is dan 5.
- Wanneer de $\chi^2$-benadering niet verantwoord is, kan men een  *Fisher's exact test* uitvoeren.
-  De nulhypothese van deze test is eveneens dat $X$ en $Y$ onafhankelijk zijn, en de alternatieve hypothese dat $X$ en $Y$
afhankelijk zijn.
- Een nadeel van de exacte test, is dat ze conservatiever is

```{r}
fisher.test(brcaTab2)
```

---


### 8.3.3.1. Uitbreiding naar categorische variabelen met meerdere niveaus

- $\chi^2$-toets kan ook als minstens 1 van de discrete variabelen $X$ en $Y$ meer dan 2 mogelijke waarden aanneemt

- Opnieuw: nulhypothese $H_0: X$ en $Y$ zijn onafhankelijk (niet-geassocieerd), ten opzichte van het tweezijdig alternatief $H_A: X$ en $Y$
zijn niet onafhankelijk (geassocieerd).

- Als de variabele voorgesteld op de rijen $r$ mogelijke uitkomsten heeft en die op de kolommen $c$ mogelijke uitkomsten,
dan noemt men de kruistabel die $X$ tegenover $Y$ uitzet, een $r \times c$ tabel.

- Zoals voorheen vergelijkt men het aantal geobserveerde waarden in cel $(i,j)$, $O_{ij}$ genoteerd, met het aantal verwachte waarden onder de nulhypothese, $E_{ij}$
 -Opnieuw is $E_{ij}$ product van het $i$-de rijtotaal met het $j$-de
kolomtotaal gedeeld door het algemene totaal.

\begin{equation*}
X^2 = \sum_{ij} \frac{\left (O_{ij} - E_{ij}\right)^2 }{ E_{ij}}
\end{equation*}

---

- Men kan aantonen dat ze een Chi-kwadraat verdeling volgt met $(r-1) \times
(c-1)$ vrijheidsgraden als de nulhypothese waar is.
- De continu??teitscorrectie wordt meestal niet gebruikt bij meer dan 2 rijen of
kolommen.
- **Pearson $\chi^2$ test** is analogon van de one-way variantie-analyse voor kwalitatieve i.p.v. continue variabelen.

---


```{r}
brcaTab <- table(brca$variant,brca$cancer)
chisq.test(brcaTab)
```

- Om te onderzoeken of het BRCA1 gen geassocieerd is met borstkanker, berekenen we de Pearson chi-kwadraat toets voor de case-controle studie uit Tabel \@ref(tab:leu3).
- De toetsingsgrootheid bedraagt nu `r format(chisq.test(brcaTab)$statistic,digits=4)` en volgt een Chi-kwadraat verdeling met `r chisq.test(brcaTab)$parameter` vrijheidsgraden. De kans dat zo???n $\chi^2$- verdeelde toevalsveranderlijke extremer is dan `r format(chisq.test(brcaTab)$statistic,digits=4)`, bedraagt `r format(chisq.test(brcaTab)$p.value*100,digits=2)`%.
- Op het 5% significantieniveau kunnen we dus niet besluiten dat het BRCA1 gen geassocieerd is met borstkanker.

---

# 8.4. Logistische regressie

- Raamwerk voor het modelleren van binaire data (vb. kanker vs geen kanker): *logistische regressie-modellen*.
- Binaire gegevens modelleren a.d.h.v. continue en/of dummy variabelen.

- De modellen veronderstellen dat de observaties voor subject $i=1,\ldots,n$ onafhankelijk zijn en een Bernoulli verdeling volgen.
- Het logaritme van de odds wordt dan gemodelleerd d.m.v. een lineair model, ook wel lineaire predictor genoemd:
\begin{equation}
\left\{
\begin{array}{ccl}
Y_i&\sim&B(\pi_i)\\\\
\log \frac{\pi_i}{1-\pi_i}&=&\beta_0 + \beta_1X_{i1} + \ldots + \beta_p X_{ip}
\end{array}\right.
\end{equation}

---

## 8.4.1. Categorische predictor

- Borstkanker voorbeeld: is BRCA 1 variant geassocieerd is met het krijgen van borstkanker.

- Net zoals in de anova context, factor in het regressieraamwerk d.m.v. dummy variabelen.
- 1 dummy variable minder nodig hebben dan er groepen zijn.

- Voor het BRCA 1 voorbeeld zijn dus twee dummy variabelen nodig en kunnen we de data dus modelleren met onderstaande lineaire predictor:

\begin{eqnarray*}
  \log \frac{\pi_i}{1-\pi_i} &=& \beta_0+\beta_1 x_{i1} +\beta_2 x_{i2}
\end{eqnarray*}

---

- Waarbij de predictoren dummy-variabelen zijn:
$$x_{i1} = \left\{ \begin{array}{ll}
1 & \text{ als subject $i$ heterozygoot is, Pro/Leu variant} \\
0 & \text{ als subject $i$ homozygoot is, (Pro/Pro of Leu/Leu variant)} \end{array}\right. .$$
$$x_{i2} = \left\{ \begin{array}{ll}
1 & \text{ als subject $i$ homozygoot is in de Leucine mutatie: Leu/Leu } \\
0 & \text{ als subject $i$ niet homozygoot is in de Leu/Leu variant} \end{array}\right. .$$

- Homozygositeit in het wild type allel Pro/Pro wordt voor  dit model de **referentiegroep**.

---

Het model wordt als volgt in R gefit:
```{r}
brcaLogit <- glm(cancer~variant,data=brca,family=binomial)
summary(brcaLogit)
```

Het intercept is de log-odds op kanker in de referentieklasse (Pro/Pro) en de hellingstermen zijn log odds ratio's tussen de behandeling en de referentieklasse:
\begin{eqnarray*}
\log \text{ODDS}_\text{Pro/Pro}&=&\beta_0\\\\
\log \text{ODDS}_\text{Pro/Leu}&=&\beta_0+\beta_1\\\\
\log \text{ODDS}_\text{Leu/Leu}&=&\beta_0+\beta_2\\\\
\log  \frac{\text{ODDS}_\text{Pro/Leu}}{\text{ODDS}_\text{Pro/Pro}}&=&\log \text{ODDS}_\text{Pro/Leu}-\log ODDS_{Pro/Pro}\\
&=&\beta_0+\beta_1-\beta_0=\beta_1\\\\
\log  \frac{\text{ODDS}_\text{Leu/Leu}}{\text{ODDS}_\text{Pro/Pro}}&=&\beta_2
\end{eqnarray*}

- De analyse laat dus toe om de resultaten onmiddellijk te interpreteren in termen van Odds'es en Odds-ratio's!

---

```{r}
anova(brcaLogit,test="Chisq")
```

De $\chi^2$-test op het logistische regressiemodel geeft eveneens aan dat er geen significante associatie is tussen de uitkomst (voorkomen van kanker) en de factor ( de genetische variant van het BRCA gen) ($p=$ `r format(anova(brcaLogit,test="Chisq")[2,"Pr(>Chi)"],digits=3)`).
De p-waarde is bijna equivalent aan de p-waarde van de $\chi^2$-test uit de vorige sectie.

---

- Significante associatie? Post-hoc tests om te evalueren welke odds ratio's verschillend zijn.
- Voor het BRCA1 voorbeeld zouden we uiteraard geen post-hoc testen
- Toch illustratie zodat jullie over de code beschikken


---

```{r}
suppressPackageStartupMessages({library(multcomp)})
posthoc <- glht(brcaLogit,linfct=mcp(variant = "Tukey"))
posthocTests <- summary(posthoc)
posthocTests
```

---

```{r}
posthocBI <- confint(posthoc)
posthocBI
```
- Door middel van de `confint` functie worden BI's verkregen op de log-odds ratios die gecorrigeerd zijn voor multiple testing.

---

- BI's kunnen als volgt worden teruggetransformeerd naar odds ratios:

```{r}
OR <- exp(posthocBI$confint)
OR
```

- De odds ratios die worden bekomen met het logistisch regressiemodel zijn exact gelijk aan de odds ratios die we zouden bekomen op basis van Tabel:
- vb.  $\text{OR}_\text{Leu/Leu-Pro/Pro}=89\times 266/(56\times 342)=$ `r format((89/56)/(342/266),digits=4)`.

- Merk op dat de statistische besluitvorming bij logistische modellen beroep doet op asymptotische theorie.

---

## 8.4.2. Continue predictor

- Toxicologisch effect van koolstofdisulfide (CS$_2$) op kevers.
- De centrale onderzoeksvraag is of de concentratie van CS$_2$ een effect heeft op de mortaliteit (i.e. kans op sterven) van de kevers?

**Design**
- 32 onafhankelijk experimenten
- Telkens 1 kever blootgesteld aan ????n van 8 concentraties (mg/l) van CS$_2$ voor een gegeven periode.
- De uitkomst van het experiment is: de kever sterft ($y=1$) of de kever overleeft ($y=0$).

```{r}
load("dataset/kevers.rda")
head(kevers)
table(kevers$dosis,kevers$status)
```

---

We bouwen nu een logistisch regressiemodel waarbij we de log odds modelleren in functie van de dosis $x_i$:
$$\log \frac{\pi_i}{1-\pi_i}=\beta_0+\beta_1 \times x_i.$$

```{r}
keverModel<-glm(status~dosis,data=kevers,family=binomial)
summary(keverModel)
```

----

- Intercept heeft als betekenis de log odds op mortaliteit wanneer er geen $\text{CS}_2$ gas wordt toegediend.
- Erg lage odds op sterfte ($\pi/(1-\pi)=\exp(-53.2)$) en dus op een kans die nagenoeg nul is.
- Merk op: heel sterke extrapolatie: minimum dosis in de dataset `r min(kevers$dosis)` mg/l.


- Geschatte odds ratio voor het effect van dosis op de mortaliteitskans is $\exp(0.3013)=1.35$.
- Dus bij een toename van de dosis CS$_2$ met 1 mg/l, is de odds ratio voor de mortaliteit $1.35$.

---

- We besluiten dat dit effect heel significant is ($p=$ `r round(summary(keverModel)$coef[2,4],3)`).
- Een toename in de CS$_2$  dosis doet de kans op sterven toenemen.


```{r}
dosisGrid=seq(min(kevers$dosis),max(kevers$dosis),.1)
piHat=predict(keverModel,
	      newdata=data.frame(dosis=dosisGrid),
	      type="response")
```

---

```{r,echo=FALSE}
plot(dosisGrid, piHat, type="l",ylim=c(0,1), xlab="dosis", ylab="Prob(dood)",cex.lab=1.5,cex.axis=1.5)
#omdat we meerdere observaties hebben voor elke dosis,
#zullen we berekenen hoeveel kevers er leefden voor elke dosis
#en dat uitzetten in de grafiek
#zodat de ruwe gegevens ook worden weergegeven.
tabKevers=table(kevers)
text(as.double(rownames(tabKevers)),0,labels=tabKevers[,1],cex=1.5)
text(as.double(rownames(tabKevers)),1,labels=tabKevers[,2],cex=1.5)
```
