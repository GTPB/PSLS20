---
title: "11. Categorical data analysis"
author: "Lieven Clement"
date: "statOmics, Ghent University (https://statomics.github.io)"
output:
    html_document:
      code_download: true
      theme: cosmo
      toc: true
      toc_float: true
      highlight: tango
      number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(include = TRUE, comment = NA, echo = TRUE,
                      message = FALSE, warning = FALSE)
library(Rmisc)
library(tidyverse)
library(NHANES)
```


# Introduction 

- Until now we used models for a continuous response in function of categorical or continuous predictor.
- Here we will focus on a categorical response.
- We focus on the association on a categorical outcome and a categorical predictor and touch upon methods to model a categorical outcome with a continuous response. 


---

# Test for a proportion 

##Saksen-study

- Fairly closed populatie (few migration)
- Probability that an unborn child is male?

```{r}
boys <- 3175
n <- 6155
```

- On `r n` unborn children `r boys` boys are observed.
- Is there a difference in the probability that an unborn child is a boy or a girl? 

---

- The data are derived from a binary random variable $X$

  - $X=1$ for a boy and 
  - $X=0$ for a girl.

- Note: count problem: the outcome is a count (number of boys) 

- Formally we have considered a population of unborn children where each individual is characterized by a 0 or 1.

---

## Bernoulli verdeling

- Binairy data can be modelled using a Bernoulli distribution:
  \begin{eqnarray*}
X_i &\sim& B(\pi) \text{ met}\\
B(\pi)&=&\pi^{X_i}(1-\pi)^{(1-X_i)},
\end{eqnarray*}

- it has one model parameter $\pi$

    - Expected value of $X_i$: $\text{E}[X_i]=\pi,$
    - Proportion of unborn boys (children with $X=1$) in the population.
    - Hence $\pi$ is the probability that a random individual from the population is a boy (an observation with $X=1$).

- The variance of Bernoulli data is also related to $\pi$.
$$\text{Var}[X_i]=\pi (1-\pi).$$

---

Some Bernoulli probability mass functions

```{r, out.width='100%', fig.asp=1, fig.align='center',echo=FALSE}
par(mfrow=c(1,3),pty="s")
probs=c(0.25,.5,.75)
for (i in 1:length(probs))
{
plot(c(0,1),c(1-probs[i],probs[i]),ylim=c(0,1),type="h",xaxt="n",xlab="X",ylab="Probability",main= as.expression(substitute(pi == val,list(val=probs[i]))),lwd=3)
axis(1,at=c(0,1))
}
```

---

- In the Saksen study  6155 observaties were sampled at random from the population.
- We can estimate $\pi$  using the sample mean:
$$\hat \pi = \bar X = \frac{\sum\limits_{i=1}^n X_i}{n},$$

```{r}
pi=boys/n
pi
```

In our example $\bar x =$ `r boys` / `r n` = `r format(pi*100,digits=3)`%.

---

## Binomiale test

- Is the observed probability `r format(pi*100,digit=3)`% for a male child, sufficient evidence to conclude that there is a higher chance on a boy than on a girl? 

- Statistical test for 
  $$H_0: \pi=1/2 \text{ versus } H_1: \pi\neq 1/2,$$

- We need to known the distribution of 
   - $X$ and $\bar X$
   - or of the sum $S=n\bar X$.

---


- Suppose that $H_0:\pi=1/2$ is true (boys and girls have an equal frequency in the population)
- Random sample of one individual from the population has a probability to be a boy that equals $$P(X=1)=\pi=1/2.$$
- Two children that are drawn independently :
  - Probability of $\pi=1/2$ on a boy for the first and second child (independent from each other) 
  - Outcomes $(x_1, x_2)$ for both children 4 combinantions:
    $(0,0),(0,1),(1,0)\text{ en }(1,1).$
  - Each of them has a probability of $1/4 = 1/2 \times 1/2$.

- Random variable $S$ is the some of the outcomes :

$(x_1,x_2)$|$s$|$P(S = s)$|
|:---:|:---:|:---:|
(0,0)|0|1/4|
(0,1), (1,0)|1|1/2|
(1,1)|2|1/4|

---

###General: $n$ independent samples

- Probability for $\pi$ on success ($X=1$)
- Total number of successes $S$ (sum of all values of 1) can take $n+1$ possible values
  $$S=k\text{, met }k=0,\ldots,n$$
- Distribution of $S$?
\begin{equation}
P(S=k) = \left (
\begin{array}{c}
n \\
k \\
\end{array}
\right ) \pi^k (1-\pi)^{n-k}  (\#eq:binomk)
\end{equation}
- $1-\pi$: probability on 0 for individual observation and
-  binomial coefficient
\begin{equation*}
\left (
\begin{array}{c}
n \\
k \\
\end{array}
\right ) = \frac{n \times (n-1) \times ...\times (n-k+1) }{ k!} = \frac{ n!}{ k!(n-k)! }
\end{equation*}

- In R you can calculate the probabilites on each $S=k$ with the function `dbinom(k,n,p)`


---

### Binomial Distribution

S is a:

-  *Binomial distributed random  variable toevalsveranderlijke* with *Binomial probability mass function*

- parameters

    - $n$ (total number of draws from the population, is equivalent to maximal value of the outcome)  
    - $\pi$ (probability on `success` for each draw).

- Calculate probability on $k$ success on $n$ independent draws for which each probability on a succes is $\pi$.
- For binary data X.
- e.g.: wild type vs mutant of a gene, infected or not infected with HIV, ...
- Use: Compare proportions or risks on a particular event between groups.

---

### Some Binomial probability mass functions.

```{r binoms,fig.cap='Binomiale verdelingen.', out.width='80%', fig.asp=.8, fig.align='center',echo=FALSE}
par(mfrow=c(2,2))
probs=c(0.25,.5,.75)
for (i in 1:length(probs))
{
plot(0:10,dbinom(0:10,prob=probs[i],size=10),ylim=c(0,1),type="h",xlab="X",ylab="Kans (Dichtheid)",main= as.expression(substitute(pi == val,list(val=paste(probs[i],", nobs=10")))),lwd=3)
}
plot(2925:3225,dbinom(2925:3225,prob=.5,size=n),type="h",xlab="X",ylab="Kans (Dichtheid)",main= as.expression(substitute(pi == val,list(val=paste0("0.5, nobs=",n)))))
```

---

Test statistic $$H_0:\pi=1/2\text{ vs }H_1:\pi\neq 1/2$$


- $\bar X-1/2$ or, equivalent,
- $\Delta=n(\bar X-\pi_0)=S-s_0$.
- Distribution of the latter test statistic can be derived immediately from the Binomial distribution:
  - We observe $s=$ `r boys` and thus $\delta=s-s_0=$ `r boys` $-$ `r n` $\times 0.5=$ `r boys-n/2`.
  - When boys and girls are equally likely, i.e. under $H_0:\pi=1/2$, we will get following two-sided p-value:
    $$p=\text{P}_0\left[S-s_0\geq \vert \delta\vert \right] + \text{P}_0\left[S-s_0\leq - \vert \delta\vert \right].$$

- Note, that we can rewrite it in terms of S.
$$p=\text{P}_0\left[S\geq s_0+ \vert \delta\vert \right] + \text{P}_0\left[S \leq s_0 - \vert \delta\vert \right].$$

---

- For the Saksen study we calculate:

\begin{eqnarray*}
\text{P}_0\left[S\geq s_0+ \vert \delta\vert \right] &=& P(S \geq 6155 \times 0.5 + \vert 3175 - 6155 \times 0.5\vert ) \\&=& P(S \geq 3175)\\
&= &P(S= 3175) + P(S=3176) + ... + P(S=6155)\\
& =& 0.0067\\\\
\text{P}_0\left[S \leq s_0 - \vert \delta\vert \right] &=& P(S \leq  6155 \times 0.5 - \vert 3175- 6155 \times 0.5\vert) \\&=& P(S \leq 2980)\\ &= &P(S=0) + ... + P(S=2980) \\
&=&0.0067
\end{eqnarray*}

- The Binomial distribution is symmetric for$\pi=1/2$:
$$\text{P}_0\left[S\geq s_0+ \vert \delta\vert \right] = \text{P}_0\left[S \leq s_0 - \vert \delta\vert \right]$$
- This is no longer the case when $\pi$ deviate from 0.5.  

---


```{r}
pi0 <- 0.5; s0 <- pi0 *n
delta <- abs(boys- s0)
delta

sUp <- s0 + delta
sDown <- s0 -delta
c(sDown,sUp)

pUp <- 1-pbinom(sUp-1,n,pi0)
pDown <- pbinom(sDown,n,pi0)
p <- pUp+pDown
c(pUp,pDown, p)
```

---


- If $\pi= 1/2$, the probability to observe at least  $\delta=$ `r delta` boys more or less than the mean under $H_0: s_0=$ `r s0` in a random sample is only `r format(p*100,digits=3)`% is: **$p$-value of binomial test.**  
- Very unlikely to observe such a large number of boys in a random sample when boys and girls have the same  frequency in the population (under $H_0$).
- Hence the hypothesis that the frequency of boys and girls is the same is not supported by the data. 

---

```{r, out.width='100%', fig.asp=.8, fig.align='center',echo=FALSE}
plot(s0+seq(-150.5,150.5,1),dbinom(s0+seq(-150.5,150.5,1),prob=.5,size=n),type="h",xlab="X",ylab="Probability",main= as.expression(substitute(pi == val,list(val=paste0("0.5, nobs=",n)))),ylim=c(-.0009,0.011))
abline(v=s0,lwd=2,col=4)
abline(v=boys,lwd=2,col=2)
abline(v=sDown,lwd=1,col=2,lty=2)
text(c(sDown,s0,boys,boys),c(rep(0.011,3),0.01),labels=c(expression(paste(s[0]-delta)),expression(s[0]),expression(s==s[0]+delta),as.expression(substitute(s==val,list(val=boys)))),pos=4,col=c(2,4,2))
text(sDown-50,-.0005,label="p-value",col=2,pos=4)
text(sUp,-.0005,label="p-value",col=2,pos=4)
arrows(s0+1500.5,-.0009,sUp,-.0009,col=2,lwd=2,angle=20,length=.1)
arrows(s0-1500.5,-.0009,sDown,-.0009,col=2,lwd=2,angle=20,length=.1)
```

---

The test can immediately be conducted using the `binomial.test` function in R.

```{r}
binom.test(x=boys,n=n,p=pi0)
```

On the 5% significance-level we conclude that there is on average a higher probability on a unborn male child than an unborn female child.   

---

### Confidence interval on a proportion

- Estimator of the proportion of boys in the population  is the sample mean $\hat \pi=\bar x=$ `r format(pi,digits=3)`
- The standard error is
$$SE_{\bar x}=\sqrt{\frac{\text{Var}[X]}{n}}=\sqrt{\frac{\pi(1-\pi)}{n}}$$
- We can estimate this based on the sample: $SE_{\bar x}=\sqrt{\frac{\hat\pi(1-\hat\pi)}{n}}=$ `r format(sqrt(pi*(1-pi)/n),digits=2)`.
- 95% CI via CLT: $\hat\pi \pm 1.96 SE_{\hat\pi}.$

```{r}
se=sqrt(pi*(1-pi)/n)
pi+c(-1,1)*qnorm(0.975)*se
```

---

### CI on proportion in small sample? 

```{r}
CI <- binom.test(x=boys,n=n,p=pi0)$conf.int
CI
```

---


### Conclusion

- Note that the test for a proportion is equivalent to a one-sample t-test for binary data.

- For the Saksen population we conclude at the 5% significance level that the gender of unborn children is more likely to be male than female ($p=$ `r round(binom.test(x=boys,n=n,p=pi0)$p.value,3)`).
The probability that an unborn child is male equals `r format(pi*100,digits=3)`% (95% CI [`r paste(format(CI*100,digits=3),collapse=",")`]%).

---

# Test for association between two qualitative variables 
## Paired observations

- 2 measurements on same individual
- e.g. before and after exposure to a chemical substance
- observe a categorical outcome before and after.
- *gepaarde binair responses*
- Statistical analysis has to account for paired design.

---

### Example:  Females choose gentle, but not healthy or macho males in Campbell dwarf hamsters (Rogovin et al. 2017)

```{r, out.width='70%', fig.asp=1, fig.align='center',echo=FALSE}
library(plotrix)
par(mar=c(0,0,0,0),mai=c(0,0,0,0))
plot(0,0,axes=FALSE,xlab="",ylab="",col=0,xlim=c(0,3),ylim=c(0,3))
rect(0,0,3,3)
lines(c(1,1),c(0,3))
lines(c(2,2),c(0,3))
lines(c(1,1),c(1,2),lwd=2)
lines(c(1,1),c(1,2),lwd=4)
lines(c(2,2),c(1,2),lwd=4)
rect(1.45,1,1.55,1.3)
draw.circle(1.5,1.36,0.05)
lines(c(1.5,1.5),c(1,.85))
text(1.5,1.15,"\\VE",vfont=c("sans serif","bold"),cex=1.3)
rect(0.5,1.05,0.8,1.15)
draw.circle(0.86,1.1,0.05)
lines(c(0.5,0.35),c(1.1,1.1))
lines(c(0.8,0),c(1.1,1.5),lty=2)
text(0.65,1.1,"\\MA",vfont=c("sans serif","bold"),cex=1.3)
rect(2.5,1.95,2.2,1.85)
draw.circle(2.14,1.9,0.05)
lines(c(2.5,2.65),c(1.9,1.9))
lines(c(2.2,3),c(1.9,1.5),lty=2)
text(2.35,1.9,"\\MA",vfont=c("sans serif","bold"),cex=1.3)
```

---

- The gate is opened upon 3 minutes 
- aggressive vs non-agressive male 
- Each female undergoes the test twice upon stay in

    - hostile surrounding (high population density, shortage of feed, a lot of competition)
    - gentle 


```{r catHamster, echo=FALSE}
hamster <- matrix(c(3,17,1,13),ncol=2,byrow=TRUE)
rownames(hamster) <- c("hostile-agressive", "hostile-non-agressive")
colnames(hamster) <- c("friendly-agressive","friendly-non-agressive")
hamsterTot=matrix(0,nrow=3,ncol=3)
hamsterTot[1:2,1:2]=hamster
hamsterTot[3,1:2]=colSums(hamster)
hamsterTot[,3]=rowSums(hamsterTot[,1:2])
hamsterLetters=matrix(c(" (e)"," (f)",""," (g)"," (h)","","","",""),ncol=3,byrow=TRUE)
hamsterTot=matrix(paste0(hamsterTot,hamsterLetters),byrow=FALSE,ncol=3)
colnames(hamsterTot)<-c(colnames(hamster),"total")
rownames(hamsterTot)<-c(rownames(hamster),"total")
knitr::kable(hamsterTot,booktabs = TRUE)
```

---

- $\pi_1=P[\text{agressive male } \vert \text{hostile}$
- $\hat pi_1=(e+f)/n$, with $n=e+f+g+h$.

- $\pi_0=P[\text{agressive male } \vert \text{ friendly}$
- $\hat pi_0=(e+g)/n$
-Absolute riscodifference (ARV)
\begin{equation*}
\widehat{\text{ARV}}=\hat\pi_1-\hat\pi_0=\frac{e+f}{n}-\frac{e+g}{n}=\frac{f-g}{n}
\end{equation*}
- Only affected by discordant pairs $f$ en $g$

---

- Standard error on ARV
\begin{equation*}
\text{SE}_{\widehat{\text{ARV}}}=\frac{1}{n}\sqrt{f+g-\frac{(f-g)^2}{n}}
\end{equation*}

- If we have large number of observations we can use the CLT to establish an $(1-\alpha)100\%$ CI on the ARV
$$\left[\widehat{\text{ARV}}-z_{\alpha/2}\text{SE}_{\widehat{\text{ARV}}},\widehat{\text{ARV}}-z_{\alpha/2}\text{SE}_{\widehat{\text{ARV}}}\right]$$
or
$$\left[\frac{f-g}{n}-\frac{z_{\alpha/2}}{n}\sqrt{f+g-\frac{(f-g)^2}{n}},\frac{f-g}{n}+\frac{z_{\alpha/2}}{n}\sqrt{f+g-\frac{(f-g)^2}{n}}\right] $$

---

```{r}
hamster <- matrix(c(3,17,1,13),ncol=2,byrow=TRUE)
rownames(hamster) <- c("hostile-agressive", "hostile-non-agressive")
colnames(hamster) <- c("friendly-agressive","friendly-non-agressive")

f=hamster[1,2]; g=hamster[2,1] ;n=sum(hamster)
riskdiff=(f-g)/n
riskdiff
se=sqrt(f+g-(f-g)^2/n)/n
se
ci<-riskdiff+c(-1,1)*qnorm(0.975)*se
ci
```

---

\begin{equation*}
\widehat{\text{ARV}}=\frac{17-1}{34}=0.471
\end{equation*}
of 47.1%.
- The standard error
\begin{equation*}
\text{SE}_{\widehat{\text{ARV}}}=\frac{1}{34}\sqrt{17+1-\frac{(17-1)^2}{34}}=0.0952
\end{equation*}
- A 95\% confidence on the absolute risk difference on the choice of an aggressive male between a stay in a hostile and friendly environment. 
\begin{equation*}
\left[0.471-1.96\times 0.0952,0.471+1.96\times 0.0952\right]=[0.284,0.658]
\end{equation*}

---

## McNemar test
```{r,echo=FALSE}
knitr::kable(hamsterTot,booktabs = TRUE)
```

- Assess if risk on choice for agressive male differs between stay in hostile and friendly environment.
- Only discordant pairs give information.
- $f>g$ indication against $H_0$: choice of partner not associated with environment.
- Evaluate probability that in a random discordant pair, a female chooses an agressive male upon a stay in a hostile environment.
- We estimate the probability as
  $$\frac{f}{f+g}$$

---

  \begin{eqnarray*}
  \text{E}\left[f/(f+g)\right]&\stackrel{H_0}{=}& 0.5\\
  f & \stackrel{H_0}{\sim}& \text{Binom}(n=f+g,\pi=0.5)\\
  \text{SE}_{\frac{f}{f+g}} & \stackrel{H_0}{=}& \sqrt{(f+g)\times 0.5\times 0.5}=\frac{\sqrt{f+g}}{2}
\end{eqnarray*}

---

- Asymptotically a one-sample z-test (based on the Normal distribution)

\begin{equation*}
z=\frac{f-(f+g)/2}{\sqrt{f+g}/2}=\frac{f-g}{\sqrt{f+g}}
\end{equation*}

- Normal approximation is good if $$f \times g/(f+g) \geq 5$$

The **Mc Nemar test** is the analogon of the paired t-test for binary qualitative variables.

---

In R we can conduct the analysis using the  `mcnemar.test` function
```{r}
mcnemar.test(hamster)
```


- We reject the null hypothesis at the 5% significance level 
- We conclude that the choice of partner is extremely significantly associated with the environment.

---

- Normale approximation is not optimal and we can perform an exact test using the binomiale test

```{r}
binom.test(x=f,n=f+g,p=0.5)
```

---

### Conclusie

- We conclude that the partner choice is extremely signficantly associated with the environment ($p<0.001$).
- The probability on chosing an agressive male is on average `r format(riskdiff*100,digits=3)`% higher if a female hamster resides in a hostile environment than when she resides in a friendly environment (95% CI [`r paste(format(ci*100,digits=3),collapse=",")`]%).

---

# Unpaired observations
## Genetic association study

- Are genetic polymorphisms in the BRCA1 gene associated with breastcancer?
- Retrospective case-control study with 800 breastcancer cases en 572 controls
- R object stored in `brca.rda`

```{r}
load("data/brca.rda")
head(brca)
summary(brca)
```

---

```{r, tidy=FALSE,echo=FALSE}
brcaHlp=data.frame(Genotype=c("Pro/Pro","Pro/Leu","Leu/Leu","Totaal"),Controles=c("266 (a)","250 (b)","56 (c)","572 (a+b+c)"),Cases=c("342 (d)","369 (e)","89 (f)","800 (d+e+f)"),Totaal=c("608 (a+d)","619 (b+e)","145 (c+f)","1372 (n)"))
knitr::kable(brcaHlp,
  booktabs = TRUE
)
```

- In case-controle studies kiest men een vast aantal cases en controles en spoort men voor hen op welke blootstellingen ze in het verleden ondervonden hebben.
- Dergelijke studies noemt men ook retrospectief
- Onmogelijk om het risico's and riscoverschillen op borstkanker te schatten: proportie van cases en controles weerspiegelt populatie niet!

---

```{r, tidy=FALSE,echo=FALSE}
brcaHlp=data.frame(Genotype=c("Pro/Pro","Pro/Leu","Leu/Leu","Totaal"),Controles=c("266 (a)","250 (b)","56 (c)","572 (a+b+c)"),Cases=c("342 (d)","369 (e)","89 (f)","800 (d+e+f)"),Totaal=c("608 (a+d)","619 (b+e)","145 (c+f)","1372 (n)"))
knitr::kable(brcaHlp,
  booktabs = TRUE
)
```

- Wel mogelijk om kans te schatten om allel Leu/Leu
    - cases: $\pi_1=f/(d+e+f)=89/800=11.1\%$
    - controles:$\pi_0=c/(a+b+c)=56/572=9.8\%$
- Relatief risico op blootstelling voor cases versus
controles is bijgevolg $11.1/9.8=1.14$.
- Vrouwen met borstkanker hebben dus 14% meer kans om de allelcombinatie Leu/Leu te hebben op het BRCA1 gen dan vrouwen zonder borstkanker.
- Dit suggereert een associatie, maar drukt iet uit hoeveel hoger het risico op borstkanker is voor vrouwen met de allelcombinatie Leu/Leu dan voor andere vrouwen
- Andere risicomaat?

---

\begin{equation*}
Odds=\frac{p}{1-p}
\end{equation*}
waarbij $p$ de kans is op die gebeurtenis.

Transformatie van het risico, met volgende eigenschappen:

  - de odds neemt waarden aan tussen nul en oneindig.

  - de odds is gelijk aan 1 als en slechts als de kans zelf gelijk is aan
1/2.

  - de odds neemt toe als de kans toeneemt.

- populair bij gokkers: hoeveel waarschijnlijker het is om te winnen dan om te verliezen

---

```{r, tidy=FALSE,echo=FALSE}
brcaHlp=data.frame(Genotype=c("Pro/Pro","Pro/Leu","Leu/Leu","Totaal"),Controles=c("266 (a)","250 (b)","56 (c)","572 (a+b+c)"),Cases=c("342 (d)","369 (e)","89 (f)","800 (d+e+f)"),Totaal=c("608 (a+d)","619 (b+e)","145 (c+f)","1372 (n)"))
knitr::kable(brcaHlp,
  booktabs = TRUE
)
```

Odds op allel Leu/Leu

- Cases: $\mbox{odds}_1=\frac{ f/(d+e+f)}{(d+e)/(d+e+f)}=f/(d+e)=89/711=0.125$. Vrouwen met borstkanker hebben ongeveer 8 keer meer kans om de allelcombinatie Leu/Leu niet te hebben op het BRCA1 gen dan om het wel te hebben.
- Controles: $\mbox{odds}_2=c/(a+b)=56/516=0.109$.

- Associatie tussen blootstelling en uitkomst:
$$
OR_{Leu/Leu}=\frac{\mbox{odds}_T}{\mbox{odds}_C}= \frac{f/(d+e)}{c/(a+b)}=\frac{f/(d+e)}{c/(a+b)}=1.15
$$

---


```{r, tidy=FALSE,echo=FALSE}
brcaHlp=data.frame(Genotype=c("Pro/Pro","Pro/Leu","Leu/Leu","Totaal"),Controles=c("266 (a)","250 (b)","56 (c)","572 (a+b+c)"),Cases=c("342 (d)","369 (e)","89 (f)","800 (d+e+f)"),Totaal=c("608 (a+d)","619 (b+e)","145 (c+f)","1372 (n)"))
knitr::kable(brcaHlp,
  booktabs = TRUE
)
```

- Was de bovenstaande studie echter een volledig lukrake steekproef geweest
(waarbij het aantal cases en controles niet per design werden vastgelegd),
- dan konden we daar ook de odds ratio op borstkanker berekenen voor mensen
met versus zonder het allel Leu/leu.
\begin{equation*}
OR_{case}=\frac{ \frac{ f}{c}}{ \frac{(d+e)}{(a+b)}} = \frac{f(a+b)}{c(d+e)}=OR_{Leu/Leu}=1.15,
\end{equation*}
- OR is een symmetrische maat! OR op borstkanker kan wel worden geschat!
- De odds op borstkanker is bijgevolg 15% hoger bij vrouwen met die specifieke allelcombinatie.

---

- Is verschil groot genoeg zodat we het effect die we in de steekproef zien kunnen veralgemenen naar de populatie toe.

- Hiertoe zullen we de kruistabel eerst herschrijven tot een 2x2 tabel

```{r leu4, tidy=FALSE,echo=FALSE}
brcaTab2 <- table(brca$variant2,brca$cancer)
brcaHlp2=data.frame(Genotype=c("andere","Leu/Leu","Totaal"),Controles=c("516 (a)","56 (b)","572 (a+b)"),Cases=c("711 (c)","89 (d)","800 (c+d)"),Totaal=c("1227 (a+c)","145 (b+d)","1372 (n)"))
knitr::kable(brcaHlp2,
  booktabs = TRUE
)
```

---

## 8.3.3. De Pearson Chi-kwadraat test voor ongepaarde gegevens

- Testen voor associatie tussen de categorische blootstelling (bvb. variant, X) en de categorische uitkomst (bvb. ziekte, Y).
$$H_0: \text{Er is geen associatie tussen } X \text{ en } Y \text{ vs } H_1: X \text{ en } Y \text{ zijn geassocieerd}$$

- Beschouw de rijtotalen $n_\text{andere}=a+c$, $n_\text{leu,leu}=b+d$ enerzijds en
- de kolomtotalen $n_\text{contr}=a+b$ en $n_\text{case}=c+d$ anderzijds.
- Zij verstrekken informatie over de *marginale verdeling* van de blootstelling (bvb. variant, X) en de uitkomst (bvb. ziekte, Y),
maar niet over de associatie tussen die veranderlijken.
- Onder $H_0$ zijn $X$ en $Y$ onafhankelijk zijn en verwacht men een proportie $(b+d)/n$
van $a+b$ controles met een Leu/Leu variant, of dat $(a+b)(b+d)/n$ een Leu/Leu variant hebben
- Analoog kan men verwachte aantal $E_{ij}$ berekenen dat onder de nulhypothese in *elke cel* van de $2\times 2$ tabel zou liggen.

---

- $E_{11}$ = het verwachte aantal onder $H_0$ in de (1,1)-cel = `r sum(brcaTab2[1,])` $\times$ `r sum(brcaTab2[,1])`/`r sum(brcaTab2)` = `r format(sum(brcaTab2[1,])*sum(brcaTab2[,1])/sum(brcaTab2),digits=4)` ;

- $E_{12}$ = het verwachte aantal onder $H_0$ in de (1,2)-cel = `r sum(brcaTab2[1,])` $\times$ `r sum(brcaTab2[,2])`/`r sum(brcaTab2)` = `r format(sum(brcaTab2[1,])*sum(brcaTab2[,2])/sum(brcaTab2),digits=4)` ;

- $E_{21}$ = het verwachte aantal onder $H_0$ in de (2,1)-cel = `r sum(brcaTab2[2,])` $\times$ `r sum(brcaTab2[,1])`/`r sum(brcaTab2)` = `r format(sum(brcaTab2[2,])*sum(brcaTab2[,1])/sum(brcaTab2),digits=4)` ;

- $E_{22}$ = het verwachte aantal onder $H_0$ in de (2,2)-cel = `r sum(brcaTab2[2,])` $\times$ `r sum(brcaTab2[,2])`/`r sum(brcaTab2)` = `r format(sum(brcaTab2[2,])*sum(brcaTab2[,2])/sum(brcaTab2),digits=4)` ;

Toetsstatistiek:
\begin{eqnarray*}
X^2 &=& \frac{\left (|O_{11} - E_{11}| - .5 \right)^2 }{ E_{11}} + \frac{
\left ( |O_{12} - E_{12}| - .5 \right)^2 }{E_{12} }+ \\
&&\quad\quad
\frac{ \left ( |O_{21}
- E_{21}| - .5 \right)^2 }{E_{21}}+ \frac{ \left ( |O_{22} - E_{22}| - .5
\right)^2 }{E_{22} }\\
 X^2 &\stackrel{H_0}{\longrightarrow}& \chi^2(df=1)
\end{eqnarray*}

---

```{r, out.width='100%', fig.asp=.8, fig.align='center',echo=FALSE}
grid=seq(0,10,.1)
plot(grid,dchisq(grid,1),type="l",lwd=2)
dfs=c(1,2,5)
for (i in 2:3)
	lines(grid,dchisq(grid,dfs[i]),col=i,lwd=2)
legend("topright",lty=1,lwd=2,col=1:3,legend=sapply(dfs, function(d) as.expression(substitute(chi[df==val]^2,list(val=d)))))
```

---

- Een grote waarde van de toetsingsgrootheid geeft een indicatie van een
afwijking van de nulhypothese.
- Concreet zal een toets op het $\alpha 100\%$
significantieniveau de nulhypothese verwerpen zodra de geobserveerde waarde
van de toetsingsgrootheid het $100\%(1-\alpha)$-percentiel, $\chi^2_{1,
\alpha}$, van de $\chi^2_1$-verdeling overschrijdt.
- Ze kan niet verwerpen in
het andere geval.
- De p-waarde voor een 2-zijdige toets is in dit geval de
kans om een grotere waarde voor de toetsingsgrootheid te observeren dan de
geobserveerde waarde $x^2$ als de nulhypothese waar is.
- Dit is de kans dat
een $\chi^2_1$-verdeelde toevalsveranderlijke waarden groter dan $x^2$
aanneemt.

---

```{r}
expected <- matrix(0,nrow=2,ncol=2)
for (i in 1:2)
	for (j in 1:2)
		expected[i,j] <-
			sum(brcaTab2[i,])*sum(brcaTab2[,j])/sum(brcaTab2)
expected
x2 <- sum((abs(brcaTab2-expected) - .5)^2/expected)
1-pchisq(x2,1)
```

---

- Omdat de observaties $O_{ij}$ in feite discrete getallen zijn, kan de
toetsingsgrootheid $X^2$ slechts discrete waarden aannemen en kan een
continue verdeling zoals de $\chi^2_1$-verdeling slechts een benadering zijn
voor haar werkelijke verdeling.
- Om de discrete verdeling beter bij de
continue $\chi^2_1$-verdeling te doen aansluiten, heeft men in de
uitdrukking van de toetsingsgrootheid voor elke cel telkens 0.5 afgetrokken.
- Dit wordt een
*continu??teitscorrectie* genoemd.
- In dit geval gaat het om de
correctie van Yates en noemt men deze toets dan ook de *Pearson
Chi-kwadraat toets met Yates correctie*.
- Wanneer de correctie niet gebruikt
wordt (d.w.z. wanneer de getallen `0.5' in de uitdrukking voor $X^2$ door 0
vervangen worden), dan spreekt men van de *Pearson Chi-kwadraat toets*.

---

In R kan je deze toetsen uitvoeren door de optie \texttt{correct} op TRUE of FALSE te zetten:

```{r}
chisq.test(brcaTab2)
chisq.test(brcaTab2,correct=FALSE)
```

---

- Zelfs met continu??teitscorrectie is $\chi^2_1$ benadering slechts
verantwoord als in geen enkele van de cellen het verwachte aantal onder
$H_0$ kleiner is dan 5.
- Wanneer de $\chi^2$-benadering niet verantwoord is, kan men een  *Fisher's exact test* uitvoeren.
-  De nulhypothese van deze test is eveneens dat $X$ en $Y$ onafhankelijk zijn, en de alternatieve hypothese dat $X$ en $Y$
afhankelijk zijn.
- Een nadeel van de exacte test, is dat ze conservatiever is

```{r}
fisher.test(brcaTab2)
```

---


### 8.3.3.1. Uitbreiding naar categorische variabelen met meerdere niveaus

- $\chi^2$-toets kan ook als minstens 1 van de discrete variabelen $X$ en $Y$ meer dan 2 mogelijke waarden aanneemt

- Opnieuw: nulhypothese $H_0: X$ en $Y$ zijn onafhankelijk (niet-geassocieerd), ten opzichte van het tweezijdig alternatief $H_A: X$ en $Y$
zijn niet onafhankelijk (geassocieerd).

- Als de variabele voorgesteld op de rijen $r$ mogelijke uitkomsten heeft en die op de kolommen $c$ mogelijke uitkomsten,
dan noemt men de kruistabel die $X$ tegenover $Y$ uitzet, een $r \times c$ tabel.

- Zoals voorheen vergelijkt men het aantal geobserveerde waarden in cel $(i,j)$, $O_{ij}$ genoteerd, met het aantal verwachte waarden onder de nulhypothese, $E_{ij}$
 -Opnieuw is $E_{ij}$ product van het $i$-de rijtotaal met het $j$-de
kolomtotaal gedeeld door het algemene totaal.

\begin{equation*}
X^2 = \sum_{ij} \frac{\left (O_{ij} - E_{ij}\right)^2 }{ E_{ij}}
\end{equation*}

---

- Men kan aantonen dat ze een Chi-kwadraat verdeling volgt met $(r-1) \times
(c-1)$ vrijheidsgraden als de nulhypothese waar is.
- De continu??teitscorrectie wordt meestal niet gebruikt bij meer dan 2 rijen of
kolommen.
- **Pearson $\chi^2$ test** is analogon van de one-way variantie-analyse voor kwalitatieve i.p.v. continue variabelen.

---


```{r}
brcaTab <- table(brca$variant,brca$cancer)
chisq.test(brcaTab)
```

- Om te onderzoeken of het BRCA1 gen geassocieerd is met borstkanker, berekenen we de Pearson chi-kwadraat toets voor de case-controle studie uit Tabel \@ref(tab:leu3).
- De toetsingsgrootheid bedraagt nu `r format(chisq.test(brcaTab)$statistic,digits=4)` en volgt een Chi-kwadraat verdeling met `r chisq.test(brcaTab)$parameter` vrijheidsgraden. De kans dat zo???n $\chi^2$- verdeelde toevalsveranderlijke extremer is dan `r format(chisq.test(brcaTab)$statistic,digits=4)`, bedraagt `r format(chisq.test(brcaTab)$p.value*100,digits=2)`%.
- Op het 5% significantieniveau kunnen we dus niet besluiten dat het BRCA1 gen geassocieerd is met borstkanker.

---

# 8.4. Logistische regressie

- Raamwerk voor het modelleren van binaire data (vb. kanker vs geen kanker): *logistische regressie-modellen*.
- Binaire gegevens modelleren a.d.h.v. continue en/of dummy variabelen.

- De modellen veronderstellen dat de observaties voor subject $i=1,\ldots,n$ onafhankelijk zijn en een Bernoulli verdeling volgen.
- Het logaritme van de odds wordt dan gemodelleerd d.m.v. een lineair model, ook wel lineaire predictor genoemd:
\begin{equation}
\left\{
\begin{array}{ccl}
Y_i&\sim&B(\pi_i)\\\\
\log \frac{\pi_i}{1-\pi_i}&=&\beta_0 + \beta_1X_{i1} + \ldots + \beta_p X_{ip}
\end{array}\right.
\end{equation}

---

## 8.4.1. Categorische predictor

- Borstkanker voorbeeld: is BRCA 1 variant geassocieerd is met het krijgen van borstkanker.

- Net zoals in de anova context, factor in het regressieraamwerk d.m.v. dummy variabelen.
- 1 dummy variable minder nodig hebben dan er groepen zijn.

- Voor het BRCA 1 voorbeeld zijn dus twee dummy variabelen nodig en kunnen we de data dus modelleren met onderstaande lineaire predictor:

\begin{eqnarray*}
  \log \frac{\pi_i}{1-\pi_i} &=& \beta_0+\beta_1 x_{i1} +\beta_2 x_{i2}
\end{eqnarray*}

---

- Waarbij de predictoren dummy-variabelen zijn:
$$x_{i1} = \left\{ \begin{array}{ll}
1 & \text{ als subject $i$ heterozygoot is, Pro/Leu variant} \\
0 & \text{ als subject $i$ homozygoot is, (Pro/Pro of Leu/Leu variant)} \end{array}\right. .$$
$$x_{i2} = \left\{ \begin{array}{ll}
1 & \text{ als subject $i$ homozygoot is in de Leucine mutatie: Leu/Leu } \\
0 & \text{ als subject $i$ niet homozygoot is in de Leu/Leu variant} \end{array}\right. .$$

- Homozygositeit in het wild type allel Pro/Pro wordt voor  dit model de **referentiegroep**.

---

Het model wordt als volgt in R gefit:
```{r}
brcaLogit <- glm(cancer~variant,data=brca,family=binomial)
summary(brcaLogit)
```

Het intercept is de log-odds op kanker in de referentieklasse (Pro/Pro) en de hellingstermen zijn log odds ratio's tussen de behandeling en de referentieklasse:
\begin{eqnarray*}
\log \text{ODDS}_\text{Pro/Pro}&=&\beta_0\\\\
\log \text{ODDS}_\text{Pro/Leu}&=&\beta_0+\beta_1\\\\
\log \text{ODDS}_\text{Leu/Leu}&=&\beta_0+\beta_2\\\\
\log  \frac{\text{ODDS}_\text{Pro/Leu}}{\text{ODDS}_\text{Pro/Pro}}&=&\log \text{ODDS}_\text{Pro/Leu}-\log ODDS_{Pro/Pro}\\
&=&\beta_0+\beta_1-\beta_0=\beta_1\\\\
\log  \frac{\text{ODDS}_\text{Leu/Leu}}{\text{ODDS}_\text{Pro/Pro}}&=&\beta_2
\end{eqnarray*}

- De analyse laat dus toe om de resultaten onmiddellijk te interpreteren in termen van Odds'es en Odds-ratio's!

---

```{r}
anova(brcaLogit,test="Chisq")
```

De $\chi^2$-test op het logistische regressiemodel geeft eveneens aan dat er geen significante associatie is tussen de uitkomst (voorkomen van kanker) en de factor ( de genetische variant van het BRCA gen) ($p=$ `r format(anova(brcaLogit,test="Chisq")[2,"Pr(>Chi)"],digits=3)`).
De p-waarde is bijna equivalent aan de p-waarde van de $\chi^2$-test uit de vorige sectie.

---

- Significante associatie? Post-hoc tests om te evalueren welke odds ratio's verschillend zijn.
- Voor het BRCA1 voorbeeld zouden we uiteraard geen post-hoc testen
- Toch illustratie zodat jullie over de code beschikken


---

```{r}
suppressPackageStartupMessages({library(multcomp)})
posthoc <- glht(brcaLogit,linfct=mcp(variant = "Tukey"))
posthocTests <- summary(posthoc)
posthocTests
```

---

```{r}
posthocBI <- confint(posthoc)
posthocBI
```
- Door middel van de `confint` functie worden BI's verkregen op de log-odds ratios die gecorrigeerd zijn voor multiple testing.

---

- BI's kunnen als volgt worden teruggetransformeerd naar odds ratios:

```{r}
OR <- exp(posthocBI$confint)
OR
```

- De odds ratios die worden bekomen met het logistisch regressiemodel zijn exact gelijk aan de odds ratios die we zouden bekomen op basis van Tabel:
- vb.  $\text{OR}_\text{Leu/Leu-Pro/Pro}=89\times 266/(56\times 342)=$ `r format((89/56)/(342/266),digits=4)`.

- Merk op dat de statistische besluitvorming bij logistische modellen beroep doet op asymptotische theorie.

---

## 8.4.2. Continue predictor

- Toxicologisch effect van koolstofdisulfide (CS$_2$) op kevers.
- De centrale onderzoeksvraag is of de concentratie van CS$_2$ een effect heeft op de mortaliteit (i.e. kans op sterven) van de kevers?

**Design**
- 32 onafhankelijk experimenten
- Telkens 1 kever blootgesteld aan ????n van 8 concentraties (mg/l) van CS$_2$ voor een gegeven periode.
- De uitkomst van het experiment is: de kever sterft ($y=1$) of de kever overleeft ($y=0$).

```{r}
load("dataset/kevers.rda")
head(kevers)
table(kevers$dosis,kevers$status)
```

---

We bouwen nu een logistisch regressiemodel waarbij we de log odds modelleren in functie van de dosis $x_i$:
$$\log \frac{\pi_i}{1-\pi_i}=\beta_0+\beta_1 \times x_i.$$

```{r}
keverModel<-glm(status~dosis,data=kevers,family=binomial)
summary(keverModel)
```

----

- Intercept heeft als betekenis de log odds op mortaliteit wanneer er geen $\text{CS}_2$ gas wordt toegediend.
- Erg lage odds op sterfte ($\pi/(1-\pi)=\exp(-53.2)$) en dus op een kans die nagenoeg nul is.
- Merk op: heel sterke extrapolatie: minimum dosis in de dataset `r min(kevers$dosis)` mg/l.


- Geschatte odds ratio voor het effect van dosis op de mortaliteitskans is $\exp(0.3013)=1.35$.
- Dus bij een toename van de dosis CS$_2$ met 1 mg/l, is de odds ratio voor de mortaliteit $1.35$.

---

- We besluiten dat dit effect heel significant is ($p=$ `r round(summary(keverModel)$coef[2,4],3)`).
- Een toename in de CS$_2$  dosis doet de kans op sterven toenemen.


```{r}
dosisGrid=seq(min(kevers$dosis),max(kevers$dosis),.1)
piHat=predict(keverModel,
	      newdata=data.frame(dosis=dosisGrid),
	      type="response")
```

---

```{r,echo=FALSE}
plot(dosisGrid, piHat, type="l",ylim=c(0,1), xlab="dosis", ylab="Prob(dood)",cex.lab=1.5,cex.axis=1.5)
#omdat we meerdere observaties hebben voor elke dosis,
#zullen we berekenen hoeveel kevers er leefden voor elke dosis
#en dat uitzetten in de grafiek
#zodat de ruwe gegevens ook worden weergegeven.
tabKevers=table(kevers)
text(as.double(rownames(tabKevers)),0,labels=tabKevers[,1],cex=1.5)
text(as.double(rownames(tabKevers)),1,labels=tabKevers[,2],cex=1.5)
```
